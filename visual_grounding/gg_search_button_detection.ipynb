{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from PIL import Image, ImageDraw\n",
    "from transformers import Qwen2VLForConditionalGeneration, AutoProcessor\n",
    "from playwright.async_api import async_playwright\n",
    "from qwen_vl_utils import process_vision_info\n",
    "import torch\n",
    "\n",
    "# 1. Setup\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "if 'model' not in locals():\n",
    "    model = Qwen2VLForConditionalGeneration.from_pretrained(\"Qwen/Qwen2-VL-2B-Instruct\", dtype=\"auto\",\n",
    "                                                            device_map=device)\n",
    "    processor = AutoProcessor.from_pretrained(\"Qwen/Qwen2-VL-2B-Instruct\")\n",
    "\n",
    "\n",
    "async def find_and_verify_element(url, element_description):\n",
    "    image_path = \"page.png\"\n",
    "\n",
    "    # --- Capture ---\n",
    "    async with async_playwright() as p:\n",
    "        browser = await p.chromium.launch()\n",
    "        page = await browser.new_page()\n",
    "        await page.goto(url)\n",
    "        # Using 1024x1024 to match model training resolution often helps accuracy\n",
    "        await page.set_viewport_size({\"width\": 1024, \"height\": 1024})\n",
    "        await page.screenshot(path=image_path)\n",
    "        await browser.close()\n",
    "\n",
    "    # --- Inference ---\n",
    "    # We specifically ask for the center point to help the model allow for single-point precision\n",
    "    prompt = f\"Find the bounding box of the {element_description}.\"\n",
    "\n",
    "    messages = [{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [{\"type\": \"image\", \"image\": image_path}, {\"type\": \"text\", \"text\": prompt}]\n",
    "    }]\n",
    "\n",
    "    text = processor.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    image_inputs, video_inputs = process_vision_info(messages)\n",
    "    inputs = processor(text=[text], images=image_inputs, padding=True, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    generated_ids = model.generate(**inputs, max_new_tokens=128)\n",
    "    output_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "    print(f\"Model said: {output_text}\")\n",
    "\n",
    "    # --- Parse (The 'Chat' Logic: x, y, x, y) ---\n",
    "    # Matches (213, 372...) or [213, 372...]\n",
    "    pattern = r\"\\((\\d+),\\s*(\\d+)\\)\\s*to\\s*\\((\\d+),\\s*(\\d+)\\)\"\n",
    "    match = re.search(pattern, output_text)\n",
    "\n",
    "    if match:\n",
    "        # Chat mode usually outputs [x_min, y_min, x_max, y_max]\n",
    "        # If the result looks like a vertical strip, swap these variables.\n",
    "        norm_x1, norm_y1, norm_x2, norm_y2 = map(int, match.groups())\n",
    "\n",
    "        # Get Real Dimensions\n",
    "        img = Image.open(image_path)\n",
    "        W, H = img.size\n",
    "\n",
    "        # Convert 0-1000 to Pixels\n",
    "        x1 = (norm_x1 / 1000) * W\n",
    "        y1 = (norm_y1 / 1000) * H\n",
    "        x2 = (norm_x2 / 1000) * W\n",
    "        y2 = (norm_y2 / 1000) * H\n",
    "\n",
    "        center_x = (x1 + x2) / 2\n",
    "        center_y = (y1 + y2) / 2\n",
    "\n",
    "        print(f\"Found Coordinates: Center({center_x:.1f}, {center_y:.1f})\")\n",
    "\n",
    "        # --- Verify Visual (Python Side) ---\n",
    "        draw = ImageDraw.Draw(img)\n",
    "        # Draw Box\n",
    "        draw.rectangle([x1, y1, x2, y2], outline=\"red\", width=4)\n",
    "        # Draw Center\n",
    "        r = 10\n",
    "        draw.ellipse((center_x - r, center_y - r, center_x + r, center_y + r), fill=\"green\", outline=\"black\")\n",
    "\n",
    "        # Save/Show result\n",
    "        img.save(\"verified_result.png\")\n",
    "        return (center_x, center_y)\n",
    "    else:\n",
    "        print(\"No coordinates found.\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# Run\n",
    "# Note: If you want the gray button specifically, try prompting: \"the gray Google Search button below the text bar\"\n",
    "await find_and_verify_element(\"https://www.google.com\", \"Google Search button\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
