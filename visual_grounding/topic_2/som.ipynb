{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from transformers import Qwen2VLForConditionalGeneration, AutoProcessor, BitsAndBytesConfig\n",
    "from playwright.async_api import async_playwright\n",
    "from qwen_vl_utils import process_vision_info\n",
    "from PIL import Image\n",
    "import re\n",
    "import nest_asyncio\n",
    "from IPython.display import display\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "\n",
    "import torch\n",
    "from transformers import Qwen2VLForConditionalGeneration, AutoProcessor\n",
    "\n",
    "# 1. CLEANUP: Clear the old 4-bit model from GPU memory\n",
    "try:\n",
    "    del model\n",
    "    del processor\n",
    "    torch.cuda.empty_cache()\n",
    "except:\n",
    "    pass\n",
    "\n",
    "print(\"Initializing Qwen2-VL in HIGH DEFINITION (float16)...\")\n",
    "\n",
    "# NO BitsAndBytesConfig needed!\n",
    "# We load directly in float16.\n",
    "model = Qwen2VLForConditionalGeneration.from_pretrained(\n",
    "    \"Qwen/Qwen2-VL-2B-Instruct\",\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(\"Qwen/Qwen2-VL-2B-Instruct\")\n",
    "\n",
    "print(f\"Model loaded! VRAM used: {torch.cuda.memory_allocated()/1024**3:.2f} GB\")\n",
    "\n",
    "# --- 1. THE \"BIG MODE\" MARKER SCRIPT ---\n",
    "# Changes:\n",
    "# - Background: Yellow (High visibility)\n",
    "# - Font Size: 24px (Huge)\n",
    "# - Border: Thick Black (Clear separation)\n",
    "JS_MARKER_SCRIPT_BIG = \"\"\"\n",
    "(function() {\n",
    "    let idCounter = 0;\n",
    "    document.querySelectorAll('.som-marker').forEach(el => el.remove());\n",
    "\n",
    "    const elements = document.querySelectorAll('button, input, a, [role=\"button\"], [aria-label=\"Search by voice\"]');\n",
    "\n",
    "    elements.forEach(el => {\n",
    "        const rect = el.getBoundingClientRect();\n",
    "        if (rect.width > 10 && rect.height > 10 && rect.top >= 0 && rect.left >= 0) {\n",
    "            const id = ++idCounter;\n",
    "            el.setAttribute('data-som-id', id);\n",
    "\n",
    "            const label = document.createElement('div');\n",
    "            label.className = 'som-marker';\n",
    "            label.innerText = id;\n",
    "            label.style.position = 'fixed';\n",
    "            // Center the label on the element slightly\n",
    "            label.style.left = (rect.left) + 'px';\n",
    "            label.style.top = (rect.top) + 'px';\n",
    "\n",
    "            // VISIBILITY STYLES\n",
    "            label.style.backgroundColor = '#FFFF00'; // Bright Yellow\n",
    "            label.style.color = '#000000';           // Black Text\n",
    "            label.style.fontSize = '24px';           // HUGE FONT\n",
    "            label.style.fontWeight = '900';          // Extra Bold\n",
    "            label.style.padding = '4px 8px';\n",
    "            label.style.border = '3px solid black';  // High Contrast Border\n",
    "            label.style.zIndex = '10000';\n",
    "            label.style.pointerEvents = 'none';\n",
    "            document.body.appendChild(label);\n",
    "        }\n",
    "    });\n",
    "    return idCounter;\n",
    "})();\n",
    "\"\"\"\n",
    "\n",
    "async def run_som_agent_robust(target_description=\"microphone icon\"):\n",
    "    url = \"https://www.google.com\"\n",
    "    screenshot_path = \"som_big_mode.png\"\n",
    "\n",
    "    print(f\"--- QUEST 3: BIG MODE ---\")\n",
    "    print(f\"Target: '{target_description}'\")\n",
    "\n",
    "    async with async_playwright() as p:\n",
    "        browser = await p.chromium.launch(headless=True)\n",
    "        page = await browser.new_page(viewport={'width': 1280, 'height': 800})\n",
    "        await page.goto(url)\n",
    "        await page.wait_for_load_state(\"networkidle\")\n",
    "\n",
    "        # 1. Inject GIANT Markers\n",
    "        print(\"Injecting GIANT markers...\")\n",
    "        await page.evaluate(JS_MARKER_SCRIPT_BIG)\n",
    "        await page.wait_for_timeout(500)\n",
    "\n",
    "        # 2. Capture\n",
    "        await page.screenshot(path=screenshot_path)\n",
    "        display(Image.open(screenshot_path)) # Verify the markers are readable to YOU\n",
    "\n",
    "        # 3. The \"Point Blank\" Prompt\n",
    "        # We ask it to find the visual feature, then read the number.\n",
    "        prompt = (\n",
    "            f\"Look at the image. Find the '{target_description}'. \"\n",
    "            f\"There is a bright yellow box with a black number on top of it. \"\n",
    "            f\"What is that number?\"\n",
    "        )\n",
    "\n",
    "        messages = [{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [{\"type\": \"image\", \"image\": screenshot_path}, {\"type\": \"text\", \"text\": prompt}]\n",
    "        }]\n",
    "\n",
    "        text = processor.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "        image_inputs, video_inputs = process_vision_info(messages)\n",
    "\n",
    "        inputs = processor(\n",
    "            text=[text],\n",
    "            images=image_inputs,\n",
    "            padding=True,\n",
    "            return_tensors=\"pt\"\n",
    "        ).to(model.device)\n",
    "\n",
    "        print(\"Asking Qwen...\")\n",
    "        with torch.no_grad():\n",
    "            generated_ids = model.generate(**inputs, max_new_tokens=50)\n",
    "\n",
    "        output_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "        print(f\"ü§ñ AI Said: '{output_text}'\")\n",
    "\n",
    "        # 4. Parsing\n",
    "        # Just grab the last digit mentioned, it's usually the answer.\n",
    "        ids = re.findall(r\"(\\d+)\", output_text)\n",
    "\n",
    "        if ids:\n",
    "            target_id = ids[-1] # Take the last number found\n",
    "            print(f\"‚úÖ Target ID: {target_id}\")\n",
    "\n",
    "            selector = f'[data-som-id=\"{target_id}\"]'\n",
    "            if await page.locator(selector).count() > 0:\n",
    "                print(f\"Clicking #{target_id}...\")\n",
    "                await page.hover(selector)\n",
    "                await page.mouse.down()\n",
    "                await page.mouse.up()\n",
    "                await page.wait_for_timeout(2000)\n",
    "                await page.screenshot(path=\"success_big_mode.png\")\n",
    "                display(Image.open(\"success_big_mode.png\"))\n",
    "            else:\n",
    "                print(f\"‚ùå AI saw #{target_id}, but it's not in the DOM.\")\n",
    "        else:\n",
    "            print(\"‚ùå No numbers found in response.\")\n",
    "\n",
    "        await browser.close()\n",
    "\n",
    "# Try looking for the microphone again\n",
    "await run_som_agent_robust(\"microphone icon inside the search bar\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
