{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-05T04:25:17.465535Z",
     "start_time": "2025-12-05T04:25:17.362450Z"
    }
   },
   "source": [
    "import torch\n",
    "\n",
    "# x = torch.tensor([[3], [1], [5], [7], [4]])\n",
    "\n",
    "# torch.transpose(x, 0, 1)"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'adadelta' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m# x = torch.tensor([[3], [1], [5], [7], [4]])\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \n\u001B[1;32m      5\u001B[0m \u001B[38;5;66;03m# torch.transpose(x, 0, 1)\u001B[39;00m\n",
      "File \u001B[0;32m~/Documents/max/deep-learning-from-zero-to-hero/.venv/lib/python3.9/site-packages/torch/__init__.py:2193\u001B[0m\n\u001B[1;32m   2177\u001B[0m \u001B[38;5;66;03m################################################################################\u001B[39;00m\n\u001B[1;32m   2178\u001B[0m \u001B[38;5;66;03m# Import most common subpackages\u001B[39;00m\n\u001B[1;32m   2179\u001B[0m \u001B[38;5;66;03m################################################################################\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   2184\u001B[0m \n\u001B[1;32m   2185\u001B[0m \u001B[38;5;66;03m# needs to be before import torch.nn as nn to avoid circular dependencies\u001B[39;00m\n\u001B[1;32m   2186\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mautograd\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m (  \u001B[38;5;66;03m# usort: skip\u001B[39;00m\n\u001B[1;32m   2187\u001B[0m     enable_grad \u001B[38;5;28;01mas\u001B[39;00m enable_grad,\n\u001B[1;32m   2188\u001B[0m     inference_mode \u001B[38;5;28;01mas\u001B[39;00m inference_mode,\n\u001B[1;32m   2189\u001B[0m     no_grad \u001B[38;5;28;01mas\u001B[39;00m no_grad,\n\u001B[1;32m   2190\u001B[0m     set_grad_enabled \u001B[38;5;28;01mas\u001B[39;00m set_grad_enabled,\n\u001B[1;32m   2191\u001B[0m )\n\u001B[0;32m-> 2193\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[1;32m   2194\u001B[0m     __config__ \u001B[38;5;28;01mas\u001B[39;00m __config__,\n\u001B[1;32m   2195\u001B[0m     __future__ \u001B[38;5;28;01mas\u001B[39;00m __future__,\n\u001B[1;32m   2196\u001B[0m     _awaits \u001B[38;5;28;01mas\u001B[39;00m _awaits,\n\u001B[1;32m   2197\u001B[0m     accelerator \u001B[38;5;28;01mas\u001B[39;00m accelerator,\n\u001B[1;32m   2198\u001B[0m     autograd \u001B[38;5;28;01mas\u001B[39;00m autograd,\n\u001B[1;32m   2199\u001B[0m     backends \u001B[38;5;28;01mas\u001B[39;00m backends,\n\u001B[1;32m   2200\u001B[0m     cpu \u001B[38;5;28;01mas\u001B[39;00m cpu,\n\u001B[1;32m   2201\u001B[0m     cuda \u001B[38;5;28;01mas\u001B[39;00m cuda,\n\u001B[1;32m   2202\u001B[0m     distributed \u001B[38;5;28;01mas\u001B[39;00m distributed,\n\u001B[1;32m   2203\u001B[0m     distributions \u001B[38;5;28;01mas\u001B[39;00m distributions,\n\u001B[1;32m   2204\u001B[0m     fft \u001B[38;5;28;01mas\u001B[39;00m fft,\n\u001B[1;32m   2205\u001B[0m     futures \u001B[38;5;28;01mas\u001B[39;00m futures,\n\u001B[1;32m   2206\u001B[0m     hub \u001B[38;5;28;01mas\u001B[39;00m hub,\n\u001B[1;32m   2207\u001B[0m     jit \u001B[38;5;28;01mas\u001B[39;00m jit,\n\u001B[1;32m   2208\u001B[0m     linalg \u001B[38;5;28;01mas\u001B[39;00m linalg,\n\u001B[1;32m   2209\u001B[0m     mps \u001B[38;5;28;01mas\u001B[39;00m mps,\n\u001B[1;32m   2210\u001B[0m     mtia \u001B[38;5;28;01mas\u001B[39;00m mtia,\n\u001B[1;32m   2211\u001B[0m     multiprocessing \u001B[38;5;28;01mas\u001B[39;00m multiprocessing,\n\u001B[1;32m   2212\u001B[0m     nested \u001B[38;5;28;01mas\u001B[39;00m nested,\n\u001B[1;32m   2213\u001B[0m     nn \u001B[38;5;28;01mas\u001B[39;00m nn,\n\u001B[1;32m   2214\u001B[0m     optim \u001B[38;5;28;01mas\u001B[39;00m optim,\n\u001B[1;32m   2215\u001B[0m     overrides \u001B[38;5;28;01mas\u001B[39;00m overrides,\n\u001B[1;32m   2216\u001B[0m     profiler \u001B[38;5;28;01mas\u001B[39;00m profiler,\n\u001B[1;32m   2217\u001B[0m     sparse \u001B[38;5;28;01mas\u001B[39;00m sparse,\n\u001B[1;32m   2218\u001B[0m     special \u001B[38;5;28;01mas\u001B[39;00m special,\n\u001B[1;32m   2219\u001B[0m     testing \u001B[38;5;28;01mas\u001B[39;00m testing,\n\u001B[1;32m   2220\u001B[0m     types \u001B[38;5;28;01mas\u001B[39;00m types,\n\u001B[1;32m   2221\u001B[0m     utils \u001B[38;5;28;01mas\u001B[39;00m utils,\n\u001B[1;32m   2222\u001B[0m     xpu \u001B[38;5;28;01mas\u001B[39;00m xpu,\n\u001B[1;32m   2223\u001B[0m )\n\u001B[1;32m   2224\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msignal\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m windows \u001B[38;5;28;01mas\u001B[39;00m windows\n\u001B[1;32m   2227\u001B[0m \u001B[38;5;66;03m# Quantized, sparse, AO, etc. should be last to get imported, as nothing\u001B[39;00m\n\u001B[1;32m   2228\u001B[0m \u001B[38;5;66;03m# is expected to depend on them.\u001B[39;00m\n",
      "File \u001B[0;32m~/Documents/max/deep-learning-from-zero-to-hero/.venv/lib/python3.9/site-packages/torch/optim/__init__.py:30\u001B[0m\n\u001B[1;32m     24\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01moptim\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msparse_adam\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m SparseAdam \u001B[38;5;28;01mas\u001B[39;00m SparseAdam\n\u001B[1;32m     27\u001B[0m Adafactor\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__module__\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtorch.optim\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m---> 30\u001B[0m \u001B[38;5;28;01mdel\u001B[39;00m adadelta  \u001B[38;5;66;03m# type: ignore[name-defined] # noqa: F821\u001B[39;00m\n\u001B[1;32m     31\u001B[0m \u001B[38;5;28;01mdel\u001B[39;00m adagrad  \u001B[38;5;66;03m# type: ignore[name-defined] # noqa: F821\u001B[39;00m\n\u001B[1;32m     32\u001B[0m \u001B[38;5;28;01mdel\u001B[39;00m adam  \u001B[38;5;66;03m# type: ignore[name-defined] # noqa: F821\u001B[39;00m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'adadelta' is not defined"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c60e69990cf7429c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
